{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c36c3120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import pandas as pd # Usaremos pandas solo para mostrar la tabla bonita\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Agrego path de root\n",
    "ROOT_PATH = str(Path.cwd().parent.parent)\n",
    "if ROOT_PATH not in sys.path:\n",
    "    sys.path.append(ROOT_PATH)\n",
    "\n",
    "# Path de las imagenes\n",
    "IMG_DATA_PATH = Path(ROOT_PATH + \"/data/raw/images/all\")\n",
    "\n",
    "from src.vision.preprocessor import ImagePreprocessor\n",
    "from src.vision.segmentator import Segmentator\n",
    "from src.vision.features import FeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42ce0d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "def get_random_image(category, base_path=\"data/raw/images/all\"):\n",
    "    dir_path = os.path.join(base_path, category)\n",
    "    if not os.path.exists(dir_path): return None, None\n",
    "    files = [f for f in os.listdir(dir_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    if not files: return None, None\n",
    "    import random\n",
    "    random_file = random.choice(files)\n",
    "    return os.path.join(dir_path, random_file), cv2.imread(os.path.join(dir_path, random_file))\n",
    "\n",
    "def visualize_FeatureExtractor_pipeline():\n",
    "    # 1. Configuraci√≥n del Pipeline (Tu mejor configuraci√≥n)\n",
    "    preprocessor = ImagePreprocessor(\n",
    "        target_size = (600,800),\n",
    "        gamma = 1.7,\n",
    "        d_bFilter = 5,\n",
    "        binarization_block_size = 31,\n",
    "        binarization_C = -11,       # No puede ser mas de 11\n",
    "        open_kernel_size = (5, 5),\n",
    "        close_kernel_size = (9, 9),\n",
    "        clear_border_margin = 5\n",
    "    )\n",
    "    \n",
    "    segmentator = Segmentator(\n",
    "        min_area = 80,\n",
    "        merge_distance = 20\n",
    "    )\n",
    "    \n",
    "    extractor = FeatureExtractor()\n",
    "    \n",
    "    target_features = extractor.get_recommended_features()\n",
    "\n",
    "    categories = [\"arandelas\", \"clavos\", \"tornillos\", \"tuercas\"]\n",
    "    base_path = IMG_DATA_PATH\n",
    "    \n",
    "    print(f\"{'='*100}\")\n",
    "    print(f\"üî¨ FEATURES SELECCIONADAS PARA CLUSTERING\")\n",
    "    print(f\"   Variables ({len(target_features)}): {target_features}\")\n",
    "    print(f\"{'='*100}\\n\")\n",
    "\n",
    "    # Lista para acumular datos y mostrar tabla final\n",
    "    all_data = []\n",
    "\n",
    "    for category in categories:\n",
    "        # Obtener Imagen\n",
    "        path, raw_img = get_random_image(category, base_path)\n",
    "        if raw_img is None: continue\n",
    "        \n",
    "        filename = os.path.basename(path)\n",
    "        \n",
    "        try:\n",
    "            # Pipeline\n",
    "            binary = preprocessor.process(raw_img)\n",
    "            seg_res = segmentator.process(binary)\n",
    "            \n",
    "            bboxes = seg_result = seg_res.get(\"bounding_boxes\", [])\n",
    "            masks = seg_res.get(\"masks\", [])\n",
    "            \n",
    "            if not bboxes:\n",
    "                print(f\"‚ùå {category.upper()}: No se detectaron objetos en {filename}\")\n",
    "                continue\n",
    "\n",
    "            # Extraer Features\n",
    "            features_list = extractor.extract_features(bboxes, masks)\n",
    "            \n",
    "            # D. Mostrar Datos\n",
    "            if features_list:\n",
    "                # Ordenamos por √°rea para tomar el objeto principal y no ruido\n",
    "                main_obj = sorted(features_list, key=lambda x: x['area'], reverse=True)[0]\n",
    "                # Agregamos la etiqueta real para comparar\n",
    "                main_obj['Label'] = category.upper()\n",
    "                \n",
    "                all_data.append(main_obj)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error en {category}: {e}\")\n",
    "\n",
    "    # VISUALIZACI√ìN COMO TABLA (DataFrame)\n",
    "    if all_data:\n",
    "        df = pd.DataFrame(all_data)\n",
    "        \n",
    "        # Seleccionamos SOLO: Etiqueta + Las features recomendadas\n",
    "        cols_to_show = ['Label'] + target_features\n",
    "        \n",
    "        # Filtramos por si alguna feature no se calcul√≥ (seguridad)\n",
    "        final_cols = [c for c in cols_to_show if c in df.columns]\n",
    "        df_display = df[final_cols]\n",
    "        \n",
    "        # Formateo\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        pd.set_option('display.width', 1000)\n",
    "        pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "        \n",
    "        print(df_display.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52bd480e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "üî¨ FEATURES SELECCIONADAS PARA CLUSTERING\n",
      "   Variables (5): ['aspect_ratio', 'solidity', 'hole_confidence', 'circle_ratio', 'radius_variance']\n",
      "====================================================================================================\n",
      "\n",
      "    Label  aspect_ratio  solidity  hole_confidence  circle_ratio  radius_variance\n",
      "ARANDELAS        1.0094    0.9906           1.0000        0.9574           0.0190\n",
      "   CLAVOS       10.9625    0.5119           0.0000        0.0399           0.4678\n",
      "TORNILLOS        3.1997    0.5945           0.6667        0.1664           0.4813\n",
      "  TUERCAS        1.1102    0.9756           1.0000        0.8310           0.0484\n"
     ]
    }
   ],
   "source": [
    "visualize_FeatureExtractor_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "742e6766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Recolectando 5 im√°genes por categor√≠a...\n",
      "‚öôÔ∏è  Ejecutando pipeline de visi√≥n (Preproceso -> Segmentaci√≥n -> Extracci√≥n)...\n",
      "\n",
      "üßÆ Entrenando DataPreprocessor con 20 muestras...\n",
      "\n",
      "====================================================================================================\n",
      "üìä COMPARATIVA: CRUDO vs NORMALIZADO (Z-SCORE)\n",
      "====================================================================================================\n",
      "\n",
      "üîπ EJEMPLO: ARANDELAS\n",
      "----------------------------------------------------------------------------------------------------\n",
      "       aspect_ratio  solidity  hole_confidence  circle_ratio  radius_variance\n",
      "Crudo        1.0154    0.9894           1.0000        0.9623           0.0189\n",
      "Norm.        1.0154    0.9894           1.0000        0.9623           0.0189\n",
      "\n",
      "üîπ EJEMPLO: CLAVOS\n",
      "----------------------------------------------------------------------------------------------------\n",
      "       aspect_ratio  solidity  hole_confidence  circle_ratio  radius_variance\n",
      "Crudo        8.2201    0.4136           0.0000        0.0426           0.5629\n",
      "Norm.        8.2201    0.4136           0.0000        0.0426           0.5629\n",
      "\n",
      "üîπ EJEMPLO: TORNILLOS\n",
      "----------------------------------------------------------------------------------------------------\n",
      "       aspect_ratio  solidity  hole_confidence  circle_ratio  radius_variance\n",
      "Crudo        2.2280    0.5916           0.0000        0.2296           0.4456\n",
      "Norm.        2.2280    0.5916           0.0000        0.2296           0.4456\n",
      "\n",
      "üîπ EJEMPLO: TUERCAS\n",
      "----------------------------------------------------------------------------------------------------\n",
      "       aspect_ratio  solidity  hole_confidence  circle_ratio  radius_variance\n",
      "Crudo        1.0812    0.9799           1.0000        0.8339           0.0472\n",
      "Norm.        1.0812    0.9799           1.0000        0.8339           0.0472\n",
      "\n",
      "====================================================================================================\n",
      "‚úÖ VALIDACI√ìN ESTAD√çSTICA DE LA MATRIZ DE SALIDA\n",
      "   (Esperado: Media ~ 0.0 | Desviaci√≥n Std ~ 1.0)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "             aspect_ratio  solidity  hole_confidence  circle_ratio  radius_variance\n",
      "Media Final        3.4858    0.7473           0.5000        0.4969           0.2810\n",
      "Std Final          3.1095    0.2411           0.5000        0.3982           0.2507\n"
     ]
    }
   ],
   "source": [
    "from src.vision.data_prep import DataPreprocessor\n",
    "\n",
    "def get_images_batch(base_path=\"data/raw/images/all\", samples_per_class=5):\n",
    "    \"\"\"Recolecta un lote de im√°genes para tener estad√≠stica suficiente.\"\"\"\n",
    "    batch = []\n",
    "    categories = [\"arandelas\", \"clavos\", \"tornillos\", \"tuercas\"]\n",
    "    \n",
    "    print(f\"üì¶ Recolectando {samples_per_class} im√°genes por categor√≠a...\")\n",
    "    \n",
    "    for category in categories:\n",
    "        dir_path = os.path.join(base_path, category)\n",
    "        if not os.path.exists(dir_path): continue\n",
    "        \n",
    "        files = [f for f in os.listdir(dir_path) if f.lower().endswith(('.jpg', '.png'))]\n",
    "        # Tomamos los primeros N (o aleatorios)\n",
    "        selected_files = files[:samples_per_class]\n",
    "        \n",
    "        for f in selected_files:\n",
    "            path = os.path.join(dir_path, f)\n",
    "            batch.append({\n",
    "                'path': path,\n",
    "                'category': category.upper(),\n",
    "                'filename': f\n",
    "            })\n",
    "    return batch\n",
    "\n",
    "def visualize_DataPreprocessor_pipeline():\n",
    "    # 1. Instanciar Pipeline Completo\n",
    "    img_prep = ImagePreprocessor(\n",
    "        target_size = (600,800),\n",
    "        gamma = 1.7,\n",
    "        d_bFilter = 5,\n",
    "        binarization_block_size = 31,\n",
    "        binarization_C = -11,\n",
    "        open_kernel_size = (5, 5),\n",
    "        close_kernel_size = (9, 9),\n",
    "        clear_border_margin = 5\n",
    "    )\n",
    "    \n",
    "    segmentator = Segmentator(\n",
    "        min_area = 80,\n",
    "        merge_distance = 20\n",
    "    )\n",
    "    \n",
    "    extractor = FeatureExtractor()\n",
    "    data_prep = DataPreprocessor() # El nuevo integrante\n",
    "\n",
    "    # 2. Obtener Datos Crudos (Feature Extraction)\n",
    "    raw_dataset = []\n",
    "    \n",
    "    batch = get_images_batch(base_path=IMG_DATA_PATH)\n",
    "    print(\"‚öôÔ∏è  Ejecutando pipeline de visi√≥n (Preproceso -> Segmentaci√≥n -> Extracci√≥n)...\")\n",
    "\n",
    "    for item in batch:\n",
    "        try:\n",
    "            # A. Cargar\n",
    "            raw_img = cv2.imread(item['path'])\n",
    "            if raw_img is None: continue\n",
    "\n",
    "            # B. Visi√≥n\n",
    "            binary = img_prep.process(raw_img)\n",
    "            seg_res = segmentator.process(binary)\n",
    "            \n",
    "            # C. Extracci√≥n\n",
    "            features = extractor.extract_features(seg_res['bounding_boxes'], seg_res['masks'])\n",
    "            \n",
    "            if features:\n",
    "                # Tomamos el objeto principal\n",
    "                main_obj = sorted(features, key=lambda x: x.get('area', 0), reverse=True)[0]\n",
    "                main_obj['Label_Real'] = item['category'] # Guardamos etiqueta para referencia\n",
    "                raw_dataset.append(main_obj)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Error en {item['filename']}: {e}\")\n",
    "\n",
    "    if not raw_dataset:\n",
    "        print(\"‚ùå No se extrajeron caracter√≠sticas.\")\n",
    "        return\n",
    "\n",
    "    # 3. NORMALIZACI√ìN (DataPreprocessor)\n",
    "    print(f\"\\nüßÆ Entrenando DataPreprocessor con {len(raw_dataset)} muestras...\")\n",
    "    \n",
    "    # Obtenemos las columnas oficiales\n",
    "    target_features = extractor.get_recommended_features()\n",
    "    \n",
    "    # FIT + TRANSFORM\n",
    "    # Esto calcula medias/std y devuelve la matriz X normalizada\n",
    "    X_normalized = data_prep.fit_transform(raw_dataset, target_features=target_features)\n",
    "\n",
    "    # 4. VISUALIZACI√ìN (Comparativa Antes/Despu√©s)\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"üìä COMPARATIVA: CRUDO vs NORMALIZADO (Z-SCORE)\")\n",
    "    print(f\"{'='*100}\")\n",
    "\n",
    "    # Creamos DataFrames para mostrar bonito\n",
    "    df_raw = pd.DataFrame(raw_dataset)\n",
    "    df_norm = pd.DataFrame(X_normalized, columns=target_features)\n",
    "    \n",
    "    # Agregamos la etiqueta al DF normalizado para saber qu√© es qu√©\n",
    "    df_norm.insert(0, 'Label', df_raw['Label_Real'])\n",
    "\n",
    "    # Tomamos 1 ejemplo representativo de cada clase para no imprimir todo\n",
    "    unique_labels = df_norm['Label'].unique()\n",
    "    \n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', 1000)\n",
    "    pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "\n",
    "    for label in unique_labels:\n",
    "        # Indices de esta clase\n",
    "        indices = df_norm.index[df_norm['Label'] == label].tolist()\n",
    "        if not indices: continue\n",
    "        \n",
    "        idx = indices[0] # Tomamos el primero\n",
    "        \n",
    "        print(f\"\\nüîπ EJEMPLO: {label}\")\n",
    "        print(\"-\" * 100)\n",
    "        \n",
    "        # Construimos una tablita comparativa para este objeto\n",
    "        comparison = {}\n",
    "        for feat in target_features:\n",
    "            val_raw = df_raw.iloc[idx][feat]\n",
    "            val_norm = df_norm.iloc[idx][feat]\n",
    "            comparison[feat] = [val_raw, val_norm]\n",
    "            \n",
    "        df_comp = pd.DataFrame(comparison, index=[\"Crudo\", \"Norm.\"])\n",
    "        print(df_comp)\n",
    "\n",
    "    # 5. VALIDACI√ìN ESTAD√çSTICA\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(\"‚úÖ VALIDACI√ìN ESTAD√çSTICA DE LA MATRIZ DE SALIDA\")\n",
    "    print(f\"   (Esperado: Media ~ 0.0 | Desviaci√≥n Std ~ 1.0)\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    means = np.mean(X_normalized, axis=0)\n",
    "    stds = np.std(X_normalized, axis=0)\n",
    "    \n",
    "    stats_df = pd.DataFrame([means, stds], columns=target_features, index=[\"Media Final\", \"Std Final\"])\n",
    "    print(stats_df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    visualize_DataPreprocessor_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virt_env_agente",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
